{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1 - Regressão Linear Bayesiana\n",
    "---\n",
    "\n",
    "A **Regressão Linear Bayesiana**, diferente da regressão linear, visa encontrar uma distribuição de probabilidade que represente os possíveis modelos lineares que representem os dados, ou seja, enquanto a regressão linear busca encontrar um vetor de pesos *w* tal que se aproxime de $y - w^{T}x \\approx 0$ , a regressão linear bayesiana busca encontrar $p(w) = \\mathcal{N}(w|\\mu,\\sigma^2)$ que também se aproxime.\n",
    "\n",
    "As implementações feitas neste notebook têm como base as explicações da seguinte [explicação](http://krasserm.github.io/2019/02/23/bayesian-linear-regression/). Entretanto, para melhor entendimento do conteúdo, todo o código foi reescrito e comentado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funções auxiliares de plot\n",
    "def plot_data(x,y, label=True):\n",
    "    if label:\n",
    "        plt.scatter(x,y,marker='o',c='k',s=50, label=\"Dados de treino\")\n",
    "    else:\n",
    "        plt.scatter(x,y,marker='o',c='k',s=50)\n",
    "    \n",
    "def plot_expected(x,y, label=True):\n",
    "    if label:\n",
    "        plt.scatter(x,y,marker='x', color='r',label=\"Valor esperado\")\n",
    "    else: \n",
    "        plt.scatter(x,y,marker='x', color='r')\n",
    "\n",
    "def plot_prediction(x,y,var, std_times=1):\n",
    "    y = y.ravel() #flatten\n",
    "    std = np.sqrt(var.ravel()) * std_times #flatten\n",
    "    \n",
    "    plt.plot(x,y, label=\"Predição\")\n",
    "    plt.fill_between(x.ravel(), y+std, y-std, alpha=.5, label=\"Incerteza\")\n",
    "    \n",
    "def plot_model(x,y, label=False):\n",
    "    if label:\n",
    "        plt.plot(x, y, 'r--', alpha=.5, label=\"Modelos a posteriori\")\n",
    "    else: \n",
    "        plt.plot(x, y, 'r--', alpha=.5)\n",
    "    \n",
    "def plot_models(x, ys):\n",
    "    plot_model(x,ys[:,0], label=True)\n",
    "    for i in range(1, ys.shape[1]):\n",
    "        plot_model(x,ys[:,i])\n",
    "        \n",
    "def plot_posteriori_distribution(mean, cov, resolution=100):\n",
    "    x = y = np.linspace(-1,1,resolution)\n",
    "    \n",
    "    grid = np.dstack(np.meshgrid(x,y)).reshape(-1,2)\n",
    "    densities = multivariate_normal.pdf(grid, mean=mean.ravel(), cov=cov).reshape(resolution, resolution)\n",
    "    \n",
    "    plt.imshow(densities, origin='lower', extent=(-1,1,-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No modelo de regressão bayesiana, os dados são representados utilizando funções de base $\\Phi$. Para este trabalho, utilizarei duas funções de base:\n",
    "\n",
    "* Função de base identidade, onde $\\Phi(X) = X$ (para a primeira questão);\n",
    "* Função de base polinomial, onde $\\Phi(X) = [x^1, x^2, ..., x^k]^T$ , onde $k$ é um número inteiro (por padrão, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_parameter(x):\n",
    "    '''Adiciona os termos independentes (parâmetro bias) aos dados'''\n",
    "    return np.concatenate([np.ones(x.shape), x], axis=1)\n",
    "\n",
    "identity_basis_function = lambda x: x\n",
    "\n",
    "def polynomial_basis_function(x, degree=5):\n",
    "    return np.concatenate([x**d for d in range(1,degree+1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como na regressão linear, vamos assumir valores iniciais para *w* (no caso, uma distribuição inicial). Essa *distribuição a priori* de *w* será, por convenção, uma distribuição com média 0 e com uma precisão $\\alpha$, tal que\n",
    "$$p(w|\\alpha) = \\mathcal{N}(w|\\alpha^{⁻1}I)$$\n",
    "\n",
    "Após N amostras, com entrada $\\Phi$ e saídas ***y***, a distribuição de *w* continua sendo uma normal, onde:\n",
    "\n",
    "* sua média é $m_N = S_N(S_0^{-1}m_0 + \\beta \\Phi^{T}y)$. Como a distribuição a priori de *w* tem média 0, a fórmula simplifica para $m_N = \\beta S_n\\Phi^{T}y$\n",
    "\n",
    "* a matriz inversa de sua variância é $S_N^{-1} = S_0^{-1} + \\beta \\Phi^T \\Phi$. Como $S_0 = \\alpha^{⁻1}I$, $S_0^{-1} = \\alpha I$. Portanto, a fórmula da inversa da variância fica $S_N^{-1} = \\alpha I + \\beta \\Phi^T \\Phi$\n",
    "\n",
    "Agora que temos a distribuição a posteriori de w $p(w| x,\\textbf{y}, \\alpha, \\beta) = \\mathcal{N}(w|m_N, S_N)$, podemos encontrar as distribuições preditivas $p(t| x,\\textbf{y}, \\alpha, \\beta) = \\mathcal{N}(t|m_N^T \\Phi(x), \\sigma_N^2(x))$, onde $\\sigma_N^2(x) = \\frac{1}{\\beta} + \\Phi(x)^T S_N \\Phi(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posteriori(x, y, alpha, beta):\n",
    "    '''p(w|t) = N(w|mean,var)'''\n",
    "    var_inv = alpha*np.eye(x.shape[1]) + beta*x.T.dot(x) # var_inv = alpha * I + beta * xT * x\n",
    "    var = np.linalg.inv(var_inv) # var_inv_inv\n",
    "    mean = beta * var.dot(x.T).dot(y) # var * ( var_0_inv * mean_0 + beta * xT * y ), onde mean_0 = 0\n",
    "    \n",
    "    return mean, var\n",
    "\n",
    "def predict(x, mean, var, beta):\n",
    "    '''Como w segue uma distribuição normal, o valor mais provável de w será a esperança da distribuição,\n",
    "    que, no caso da normal, é a média. Logo:\n",
    "    y = x * mean\n",
    "    '''\n",
    "    y = x.dot(mean)\n",
    "    var = (1 / beta) + np.sum(x.dot(var) * x, axis = 1)\n",
    "    \n",
    "    return y, var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função auxiliar abaixo condensa o fluxo principal do treinamento:\n",
    "* é carregado um conjunto de dados de um arquivo;\n",
    "* é aplicada uma função de base sobre X\n",
    "* é pega uma amostra de tamanho N dos dados\n",
    "* o modelo é treinado com N amostras\n",
    "* são realizados os plots de:\n",
    "    * densidade da probabilidade a posteriori dos pesos\n",
    "    * 5 modelos que seguem a distribuição da posteriori, bem como os valores esperados da predição\n",
    "    * a esperança da posteriori, com uma margem de 2 desvios padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot_function(file, samples_sizes=[1, 3, 5, 7, 10], basis_function=identity_basis_function, figsize=(20,20), models_title=True):\n",
    "    data = np.loadtxt(file, delimiter=',')\n",
    "    data = data[np.argsort(data[:,0])]\n",
    "    X = data[:,0].reshape(-1,1)\n",
    "    Y = data[:,1].reshape(-1,1)\n",
    "\n",
    "    phi = add_bias_parameter(basis_function(X))\n",
    "\n",
    "    n_experiments = len(samples_sizes)\n",
    "    \n",
    "    n_plots = 3\n",
    "    if phi.shape[1] > 2:\n",
    "        n_plots = 2\n",
    "    \n",
    "    def plot(alpha, beta):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.subplots_adjust(hspace=.4)\n",
    "\n",
    "        for i, n in enumerate(samples_sizes):\n",
    "            # obtendo os elementos da amostra\n",
    "            x_n = X[:n]\n",
    "            phi_n = phi[:n] # dados de treino\n",
    "            y_n = Y[:n] # valores de saída\n",
    "\n",
    "            # treinando o modelo\n",
    "            mean, var = posteriori(phi_n, y_n, alpha, beta) # computando a posteriori de w\n",
    "            y, y_var = predict(phi, mean, var, beta) # prevendo valores para Y, dado os parâmetros da distribuição de w\n",
    "\n",
    "            # obtendo 5 exemplos de modelo a partir da distribuição de w\n",
    "            models_samples = np.random.multivariate_normal(mean.ravel(), var, 5).T # como w segue uma distribuição normal, os modelos gerados aleatoriamente seguind oessa distruibuição representam bem os dados\n",
    "            prediction_samples = phi.dot(models_samples) # realizando a predição de Y utilizando os modelos \n",
    "\n",
    "            # plots\n",
    "            plot_i = 1\n",
    "            if n_plots == 3:\n",
    "                plt.subplot(n_experiments, n_plots, i*n_plots + plot_i)\n",
    "                plot_posteriori_distribution(mean, var) # distribuição posteriori dos pesos a partir das amostras\n",
    "                plt.title(f\"Posteriori com {n} amostras\")\n",
    "                \n",
    "                plot_i += 1\n",
    "\n",
    "            plt.subplot(n_experiments, n_plots, i*n_plots + plot_i)\n",
    "            plot_expected(X, Y) # valores esperados para a predição\n",
    "            plot_data(x_n, y_n) # valores utilizados para o treinamento do modelo\n",
    "            plot_models(X, prediction_samples) # valores preditos pelos modelos que seguem a distribuição calculada\n",
    "            if models_title:\n",
    "                var_string = str(np.diag(np.round(var, 3)))\n",
    "                plt.title(f\"Médias: {np.round(mean.ravel(), 3)} | Var. : {var_string} | Cov. : {np.round(var[0,1], 3)}\")\n",
    "            else:\n",
    "                plt.title(f\"Modelos gerados analisando {n} amostras\")\n",
    "            plt.legend()   \n",
    "            \n",
    "            plot_i += 1\n",
    "\n",
    "            plt.subplot(n_experiments, n_plots, i*n_plots + plot_i)\n",
    "            plot_expected(X, Y, label=False) # valores esperados para a predição\n",
    "            plot_data(x_n, y_n, label=False) # valores utilizados para o treinamento do modelo\n",
    "            plot_prediction(X, y, np.sqrt(y_var), std_times=2) # valores predito pela esperança da distribuição de w\n",
    "            plt.title(f\"Variância média: {np.round(np.mean(y_var), 3)}\")\n",
    "            plt.legend()\n",
    "            \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1\n",
    "\n",
    "Implemente um modelo de regressão linear Bayesiana para os dados disponı́veis em *linear_regression_data.csv*.\n",
    "\n",
    "* Apresente um gráfico contendo os dados e uma representação da distribuição preditiva encontrada.\n",
    "\n",
    "* Esta representação consistirá na curva da média e nas curvas da média mais 2 desvios padrões e média menos 2 desvios padrões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863ab32ffc1e4def84ca08cb665eba34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='alpha', min=1), IntSlider(value=50, description='beta', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot = interactive(generate_plot_function(\"linear_regression_data.csv\"), \n",
    "                               alpha=widgets.IntSlider(min=1, max=100, value=2),\n",
    "                              beta=widgets.IntSlider(min=1, max=100, value=50))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2\n",
    "\n",
    "Implemente um modelo de regressão polinomial Bayesiana para os dados disponı́veis em *polynomial_regression_data.csv*.\n",
    "\n",
    "* Utilize um modelo polinomial de grau 5.\n",
    "* Apresente um gráfico contendo os dados e uma representação da distribuição preditiva encontrada (escolha um método de aproximação).\n",
    "* Esta representação consistirá na curva da média e nas curvas da média mais 2 desvios padrões e média menos 2 desvios padrões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ccded21b9c41c98f4f6fa9bf99cde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='alpha', min=1), IntSlider(value=50, description='beta', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot = interactive(\n",
    "    generate_plot_function(\n",
    "        \"polynomial_regression_data.csv\", \n",
    "        basis_function=polynomial_basis_function,\n",
    "        figsize=(10,20),\n",
    "        models_title=False\n",
    "    ), \n",
    "    alpha=widgets.IntSlider(min=1, max=100, value=2),\n",
    "    beta=widgets.IntSlider(min=1, max=100, value=50)\n",
    ")\n",
    "interactive_plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
